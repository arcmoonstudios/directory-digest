
Directory: src
File: config.ts
===============
/* src/config.ts */
/**
 * @file Centralized configuration for file and directory exclusion rules.
 * @packageDocumentation
 *
 * @remarks
 * # Directory Digest – Exclusion Configuration Module
 *▫~•◦------------------------------------------------------------‣
 *
 * This module is designed for integration into ArcMoon Code Analysis System to achieve consistent and efficient file system traversal by defining global exclusion rules.
 *
 * ### Key Capabilities
 * - **File Extension Exclusion:** Provides a comprehensive list of file extensions that should be ignored during scans, such as compiled binaries, archives, and temporary files.
 * - **Directory Exclusion:** Defines a set of directory names (e.g., build outputs, version control folders, package manager caches) to be excluded from processing.
 * - **Specific Filename Exclusion:** Lists explicit filenames (like lockfiles or system-generated artifacts) that are to be bypassed by tools.
 *
 * ### Architectural Notes
 * This module centralizes configuration for file system traversal and analysis tools. It is consumed by modules responsible for scanning, indexing, or processing codebases to ensure adherence to a unified exclusion policy. The constant arrays are designed for direct import and immutability.
 *
 * @see {@link CodeScannerModule} for modules consuming these configurations.
 * @see {@link FileSystemIntegrityChecker} for related validation contexts.
 * 
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

export const excludedFileExtensions: string[] = [
  '.env', '.ini', '.cfg', '.config', '.lock',
  '.exe', '.dll', '.so', '.dylib', '.class', '.pyc', '.pyo', '.pyd',
  '.obj', '.o', '.a', '.lib', '.out', '.rlib', '.rmeta',
  '.jar', '.war', '.ear', '.egg', '.wheel', '.whl', '.gem',
  '.ttf', '.otf', '.woff', '.woff2', '.eot',
  '.swp', '.cache', '.tmp', '.temp', '.swo',
  '.bin', '.dat', '.db', '.sqlite', '.sqlite3', '.mdb',
  '.pdb', '.ilk', '.exp', '.map',
  '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',
  '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.ico',
  '.mp3', '.mp4', '.wav', '.avi', '.mov',
  '.zip', '.rar', '.7z', '.tar', '.gz', '.tgz', '.bz2',
  '.iml', '.idea', '.project', '.classpath', '.settings',
  '.vscode', '.vs', '.suo', '.user', '.sln', '.xcodeproj',
  '.xcworkspace', '.DS_Store',
  '.pdf', '.svg', '.webp', '.heic', '.avif',
  '.tsbuildinfo',
  '.lcov', '.gcno', '.gcda',
  '.nupkg', '.rpm', '.deb', '.apk', '.dmg', '.iso', '.msi', '.pkg', '.appimage', '.snap',
  '.ipynb', '.bak', '.orig', '.rej', '.log'
];

export const excludedDirectories: string[] = [
  '0L', '.git', '.svn', '.hg', '.bzr', 'CVS',
  'node_modules', 'target', 'build', 'dist', 'bin', 'obj', 'out',
  '__pycache__', '.pytest_cache', '.tox', '.venv', 'venv', 'env', 'Lib', 'Scripts', 'site-packages',
  'classes', 'META-INF', 'WEB-INF',
  'bower_components', 'jspm_packages', '.npm', '.yarn',
  'vendor/bundle', '.bundle',
  'packages', 'Debug', 'Release', 'x86', 'x64', 'AnyCPU',
  '.idea', '.vscode', '.vs', '.settings', '.project', '.classpath',
  'logs', 'log', 'tmp', 'temp', 'cache', '.cache',
  'docs', 'doc', 'documentation',
  'coverage', '.nyc_output', 'htmlcov',
  '.github', '.gitlab', '.circleci', '.jenkins',
  '.docker',
  '.history', '.grunt', '.sass-cache',
  'public/hot', 'storage', 'compiled', 'uploads', 'vendor',
  '.pnpm', '.pnpm-store', '.yarn/cache', '.yarn/unplugged', '.yarn/releases', '.yarn/plugins',
  '.next', '.nuxt', '.svelte-kit', '.astro', '.docusaurus', '.vite', '.vitepress', '.parcel-cache', '.rollup.cache', '.storybook', 'storybook-static',
  '.gradle', 'gradle', '.mvn', 'Pods', 'DerivedData', '.build', '.swiftpm', 'Carthage/Build', '.cxx',
  'bazel-bin', 'bazel-out', 'bazel-testlogs', 'buck-out', '.buckd',
  '.serverless', '.aws-sam', '.terraform', '.terragrunt-cache', '.pulumi', 'cdk.out',
  '.mypy_cache', '.ruff_cache', '.nox', '.hypothesis', '.ipynb_checkpoints', '.pybuilder',
  '$RECYCLE.BIN', 'System Volume Information', '.Trashes', '.Trash', '.Trash-*', '.Spotlight-V100', '.fseventsd', 'lost+found'
];

export const excludedFileNames: string[] = [
  'Cargo.lock', 'gradle.lockfile', 'package-lock.json', 'pnpm-lock.yaml', 'yarn.lock',
  'composer.lock', 'Gemfile.lock', 'Podfile.lock', 'Package.resolved', 'go.sum', 'Pipfile.lock', 'poetry.lock',
  'Thumbs.db', 'desktop.ini', '.DS_Store',
  'npm-debug.log', 'yarn-error.log', 'lerna-debug.log'
];



Directory: src
File: extension.ts
==================
// src/extension.ts

import * as vscode from 'vscode';
import * as path from 'path';
import * as fsPromises from 'fs/promises';
import { minimatch } from 'minimatch';
import { logger } from './utils/logger.js';
import { excludedFileExtensions, excludedDirectories } from './config.js';

// Configuration interfaces
interface DigestConfig {
    outputFormat: 'Text' | 'Markdown' | 'JSON';
    maxFileSize: number;
    maxDepth: number;
    includePatterns: string[];
    excludePatterns: string[];
    configFilePath: string;
    excludedFileExtensions: string[];
    excludedDirectories: string[];
}

interface ConfigFile {
    includeDirectories?: string[];
    excludeDirectories?: string[];
    includeFiles?: string[];
    excludeFiles?: string[];
    includePatterns?: string[];
    excludePatterns?: string[];
}

interface FileEntry {
    path: string;
    relativePath: string;
    content?: string;
    size: number;
    isDirectory: boolean;
}

interface ProgressContext {
    report: (value: { message?: string; increment?: number }) => void;
    token: vscode.CancellationToken;
}

/**
 * Loads configuration from VS Code settings
 */
function loadConfiguration(): DigestConfig {
    const config = vscode.workspace.getConfiguration('directoryDigest');
    
    return {
        outputFormat: config.get<'Text' | 'Markdown' | 'JSON'>('outputFormat', 'Text'),
        maxFileSize: config.get<number>('maxFileSize', 1048576), // 1MB default
        maxDepth: config.get<number>('maxDepth', 10),
        includePatterns: config.get<string[]>('includePatterns', []),
        excludePatterns: config.get<string[]>('excludePatterns', []),
        configFilePath: config.get<string>('configFilePath', '.ddconfig'),
        excludedFileExtensions: config.get<string[]>('appendContent.excludedFileExtensions', excludedFileExtensions),
        excludedDirectories: config.get<string[]>('appendContent.excludedDirectories', excludedDirectories)
    };
}

/**
 * Loads and parses .ddconfig file if it exists
 */
async function loadConfigFile(baseDir: string, configFileName: string): Promise<ConfigFile | null> {
    const configPath = path.join(baseDir, configFileName);
    
    try {
        const configContent = await fsPromises.readFile(configPath, 'utf-8');
        const configData = JSON.parse(configContent) as ConfigFile;
        logger.info(`Loaded config file: ${configPath}`);
        return configData;
    } catch (err) {
        if ((err as { code?: string }).code !== 'ENOENT') {
            logger.warn(`Failed to load config file ${configPath}: ${err}`);
        }
        return null;
    }
}

/**
 * Shows user-friendly error message with retry option
 */
async function showErrorWithRetry(message: string, error: unknown): Promise<boolean> {
    const errorMsg = error instanceof Error ? error.message : String(error);
    const action = await vscode.window.showErrorMessage(
        `${message}: ${errorMsg}`,
        'Retry',
        'Cancel'
    );
    return action === 'Retry';
}

// Helper functions that were previously not exported
export function sanitizeFilename(filename: string): string {
    const ext = path.extname(filename);
    const basename = path.basename(filename, ext);
    const sanitized = basename.replace(/[^a-zA-Z0-9-]/g, '_');
    return `${sanitized}${ext}`;
}

export function shouldExcludeDirectory(dirName: string, config?: DigestConfig, configFile?: ConfigFile | null): boolean {
    const exclusions = config?.excludedDirectories || excludedDirectories;
    
    // Check config file exclusions
    if (configFile?.excludeDirectories?.includes(dirName)) {
        return true;
    }
    
    return exclusions.some((excl: string) => {
        if (excl.includes('*')) {
            const regex = new RegExp(`^${excl.replace(/\*/g, '.*')}$`);
            return regex.test(dirName);
        }
        return excl === dirName;
    });
}

export function shouldExcludeFile(fileName: string, config?: DigestConfig, configFile?: ConfigFile | null): boolean {
    const fileExt = path.extname(fileName).toLowerCase();
    const exclusions = config?.excludedFileExtensions || excludedFileExtensions;
    
    // Check config file exclusions
    if (configFile?.excludeFiles?.includes(fileName)) {
        return true;
    }
    
    return exclusions.some((excl: string) => {
        if (excl.includes('*')) {
            const regex = new RegExp(`^${excl.replace(/\*/g, '.*')}$`);
            return regex.test(fileExt);
        }
        return fileExt === excl;
    });
}

/**
 * Checks if a file matches the include/exclude patterns
 */
function matchesPatterns(filePath: string, config: DigestConfig, configFile?: ConfigFile | null): boolean {
    const relativePath = filePath;
    
    // Check config file patterns first
    if (configFile?.includePatterns?.length) {
        const matchesInclude = configFile.includePatterns.some(pattern => minimatch(relativePath, pattern));
        if (!matchesInclude) return false;
    }
    
    if (configFile?.excludePatterns?.length) {
        const matchesExclude = configFile.excludePatterns.some(pattern => minimatch(relativePath, pattern));
        if (matchesExclude) return false;
    }
    
    // Check VS Code config patterns
    if (config.includePatterns.length > 0) {
        const matchesInclude = config.includePatterns.some(pattern => minimatch(relativePath, pattern));
        if (!matchesInclude) return false;
    }
    
    if (config.excludePatterns.length > 0) {
        const matchesExclude = config.excludePatterns.some(pattern => minimatch(relativePath, pattern));
        if (matchesExclude) return false;
    }
    
    return true;
}

/**
 * Checks if file size is within limits
 */
async function isFileSizeAllowed(filePath: string, maxFileSize: number): Promise<boolean> {
    try {
        const stats = await fsPromises.stat(filePath);
        return stats.size <= maxFileSize;
    } catch (err) {
        logger.warn(`Failed to check file size for ${filePath}: ${err}`);
        return false;
    }
}

export function isTextFile(filePath: string): boolean {
    const textFileExtensions = [
        '.txt', '.md', '.js', '.ts', '.json', '.html', '.css', '.py', '.java', '.c', '.cpp',
        '.rs', '.go', '.rb', '.php', '.sql', '.xml', '.yaml', '.yml', '.toml', '.ini'
    ];
    return textFileExtensions.includes(path.extname(filePath).toLowerCase());
}

/**
 * Formats file entry content based on the specified output format
 */
function formatFileEntry(entry: FileEntry, format: 'Text' | 'Markdown' | 'JSON'): string {
    switch (format) {
        case 'Markdown':
            if (entry.isDirectory) {
                return `## Directory: ${entry.relativePath}\n\n`;
            } else {
                const extension = path.extname(entry.path).slice(1) || 'text';
                return `### File: ${entry.relativePath}\n\n\`\`\`${extension}\n${entry.content || ''}\n\`\`\`\n\n`;
            }
        
        case 'JSON':
            return JSON.stringify(entry, null, 2) + '\n';
        
        case 'Text':
        default:
            if (entry.isDirectory) {
                return `\nDirectory: ${entry.relativePath}\n${'='.repeat(entry.relativePath.length + 11)}\n\n`;
            } else {
                const header = `\nFile: ${entry.relativePath}\n${'='.repeat(entry.relativePath.length + 6)}\n`;
                return header + (entry.content || '') + '\n\n';
            }
    }
}

/**
 * Gets the appropriate file extension for the output format
 */
function getOutputExtension(format: 'Text' | 'Markdown' | 'JSON'): string {
    switch (format) {
        case 'Markdown': return '.md';
        case 'JSON': return '.json';
        case 'Text':
        default: return '.txt';
    }
}

/**
 * Wraps JSON output with proper structure
 */
function wrapJSONOutput(entries: FileEntry[], dirName: string): string {
    const output = {
        directory: dirName,
        generated: new Date().toISOString(),
        entries: entries
    };
    return JSON.stringify(output, null, 2);
}

/**
 * Creates a single file containing all directory contents with enhanced configuration support
 */
export async function appendDirectoryContent(selectedDir: string, progressContext?: ProgressContext): Promise<void> {
    const config = loadConfiguration();
    const configFile = await loadConfigFile(selectedDir, config.configFilePath);
    const dirName = path.basename(selectedDir);
    const outputExtension = getOutputExtension(config.outputFormat);
    
    // Create dot-prefixed directory for output
    const dotDirName = `.${sanitizeFilename(dirName)}Files`;
    const outputDir = path.join(selectedDir, dotDirName);
    const outputFile = path.join(outputDir, `${sanitizeFilename(dirName)}${outputExtension}`);
    
    const entries: FileEntry[] = [];
    let processedFiles = 0;
    let totalFiles = 0;

    // Check if path exists and is a directory
    let dirExists = false;
    try {
        const stats = await fsPromises.stat(selectedDir);
        dirExists = stats.isDirectory();
    } catch (err: unknown) {
        if ((err as { code?: string }).code !== 'ENOENT') {
            throw err;
        }
        // For ENOENT, dirExists remains false
    }

    if (!dirExists) {
        // Create empty output for non-existent directory
        await fsPromises.mkdir(outputDir, { recursive: true });
        logger.info(`Created output directory for non-existent directory: ${outputDir}`);
        
        const outputContent = '';
        
        await fsPromises.writeFile(outputFile, outputContent, 'utf-8');
        logger.info(`Created empty digest for non-existent directory: ${outputFile}`);
        
        progressContext?.report({ message: 'Created empty digest for non-existent directory' });
        return;
    }

    // First pass: count total files for progress tracking
    async function countFiles(dir: string, depth: number = 0): Promise<number> {
        if (depth >= config.maxDepth) {
            return 0;
        }

        try {
            const dirEntries = await fsPromises.readdir(dir, { withFileTypes: true });
            let count = 0;

            for (const entry of dirEntries) {
                const fullPath = path.join(dir, entry.name);
                const relativePath = path.relative(selectedDir, fullPath);

                if (entry.isSymbolicLink()) {
                    continue;
                }

                if (entry.isDirectory()) {
                    if (!shouldExcludeDirectory(entry.name, config, configFile ?? undefined)) {
                        count += await countFiles(fullPath, depth + 1);
                    }
                } else if (entry.isFile()) {
                    if (!shouldExcludeFile(entry.name, config, configFile ?? undefined) &&
                        matchesPatterns(relativePath, config, configFile ?? undefined) &&
                        await isFileSizeAllowed(fullPath, config.maxFileSize)) {
                        count++;
                    }
                }
            }
            return count;
        } catch (err) {
            logger.error(`Failed to count files in directory ${dir}: ${err}`);
            return 0;
        }
    }

    async function processFile(filePath: string): Promise<void> {
        try {
            const relativePath = path.relative(selectedDir, filePath);
            
            if (!await isFileSizeAllowed(filePath, config.maxFileSize)) {
                logger.warn(`File ${filePath} exceeds size limit (${config.maxFileSize} bytes)`);
                return;
            }

            if (!matchesPatterns(relativePath, config, configFile ?? undefined)) {
                return;
            }

            let content = '';
            if (isTextFile(filePath)) {
                try {
                    content = await fsPromises.readFile(filePath, 'utf-8');
                } catch (err) {
                    logger.error(`Failed to read file content ${filePath}: ${err}`);
                    content = `[Error reading file: ${err}]`;
                }
            }

            const stats = await fsPromises.stat(filePath);
            const entry: FileEntry = {
                path: filePath,
                relativePath,
                content,
                size: stats.size,
                isDirectory: false
            };

            entries.push(entry);
            processedFiles++;
            
            const progressPercent = (processedFiles / totalFiles) * 100;
            progressContext?.report({
                message: `Processed ${processedFiles}/${totalFiles} files (${progressPercent.toFixed(1)}%)`,
                increment: (1 / totalFiles) * 100
            });
            
            logger.info(`Processed file: ${filePath}`);
        } catch (err) {
            logger.error(`Failed to process file ${filePath}: ${err}`);
        }
    }

    async function processDirectory(dir: string, depth: number = 0): Promise<void> {
        if (depth >= config.maxDepth) {
            logger.warn(`Maximum depth (${config.maxDepth}) reached at: ${dir}`);
            return;
        }

        try {
            const dirEntries = await fsPromises.readdir(dir, { withFileTypes: true });
            const processPromises = dirEntries.map(async (entry) => {
                if (progressContext?.token.isCancellationRequested) {
                    throw new Error('Operation was cancelled by user');
                }

                const fullPath = path.join(dir, entry.name);
                if (entry.isSymbolicLink()) {
                    return;
                }
                
                if (entry.isDirectory() && !shouldExcludeDirectory(entry.name, config, configFile)) {
                    await processDirectory(fullPath, depth + 1);
                } else if (entry.isFile() && !shouldExcludeFile(entry.name, config, configFile)) {
                    await processFile(fullPath);
                }
            });
            await Promise.all(processPromises);
        } catch (err) {
            if (err instanceof Error && err.message.includes('cancelled')) {
                throw err;
            }
            logger.error(`Failed to process directory ${dir}: ${err}`);
        }
    }

    try {
        // First pass: count total files for progress tracking
        totalFiles = await countFiles(selectedDir);
        progressContext?.report({ message: `Processing ${totalFiles} files...` });

        await processDirectory(selectedDir);

        // Now create output directory and write
        await fsPromises.mkdir(outputDir, { recursive: true });
        logger.info(`Created output directory: ${outputDir}`);

        // Write output based on format
        let outputContent = '';
        if (config.outputFormat === 'JSON') {
            outputContent = wrapJSONOutput(entries, dirName);
        } else {
            entries.forEach(entry => {
                outputContent += formatFileEntry(entry, config.outputFormat);
            });
        }

        await fsPromises.writeFile(outputFile, outputContent, 'utf-8');
        progressContext?.report({ message: 'Writing output file...', increment: 0 });
        
        logger.info(`Successfully processed ${processedFiles} files and created: ${outputFile}`);

    } catch (err) {
        logger.error(`Failed to process directory: ${err}`);
        throw err;
    }
}

/**
 * Concatenates all files into organized structure in .{dirName} directory
 */
export async function appendAllToOutputDir(selectedDir: string): Promise<void> {
    const dirName = path.basename(selectedDir);
    const outputDir = path.join(selectedDir, `.${sanitizeFilename(dirName)}`);
    const treeFile = path.join(outputDir, `${sanitizeFilename(dirName)}.txt`);

    try {
        await fsPromises.mkdir(outputDir, { recursive: true });
        await fsPromises.writeFile(treeFile, '');
        logger.info(`Created output directory: ${outputDir}`);

        async function processFile(dir: string, filePath: string): Promise<void> {
            try {
                const relativeDir = path.relative(selectedDir, dir) || dirName;
                const parentName = sanitizeFilename(path.basename(dir));
                const outputFile = path.join(outputDir, `${parentName}.txt`);

                if (isTextFile(filePath)) {
                    const content = await fsPromises.readFile(filePath, 'utf-8');
                    const header = `\nDirectory: ${relativeDir}\nFile: ${path.basename(filePath)}\n${'='.repeat(path.basename(filePath).length + 6)}\n`;
                    await fsPromises.appendFile(outputFile, header + content + '\n\n');
                    await fsPromises.appendFile(treeFile, header + content + '\n\n');
                    logger.info(`Processed text file: ${filePath}`);
                } else {
                    const header = `\n[${path.basename(filePath)}]binary\n${'='.repeat(path.basename(filePath).length + 8)}\n`;
                    await fsPromises.appendFile(outputFile, header);
                    await fsPromises.appendFile(treeFile, header);
                    logger.info(`Processed binary file: ${filePath}`);
                }
            } catch (err) {
                logger.error(`Failed to process file ${filePath}: ${err}`);
            }
        }

        async function processDirectory(dir: string, depth: number = 0): Promise<void> {
            if (depth > 10) {
                logger.warn(`Maximum depth reached at: ${dir}`);
                return;
            }

            try {
                const entries = await fsPromises.readdir(dir, { withFileTypes: true });
                const processPromises = entries.map(async (entry) => {
                    const fullPath = path.join(dir, entry.name);
                    if (entry.isSymbolicLink()) {
                        return;
                    }
                    if (entry.isDirectory() && !shouldExcludeDirectory(entry.name)) {
                        await processDirectory(fullPath, depth + 1);
                    } else if (entry.isFile() && !shouldExcludeFile(entry.name)) {
                        await processFile(dir, fullPath);
                    }
                });
                await Promise.all(processPromises);
            } catch (err) {
                logger.error(`Failed to process directory ${dir}: ${err}`);
            }
        }

        await processDirectory(selectedDir);

        // Clean up empty files
        const files = await fsPromises.readdir(outputDir);
        await Promise.all(files.map(async (file) => {
            const filePath = path.join(outputDir, file);
            const stat = await fsPromises.stat(filePath);
            if (stat.size === 0) {
                await fsPromises.unlink(filePath);
                logger.info(`Removed empty file: ${filePath}`);
            }
        }));

        logger.info(`Successfully processed directory: ${selectedDir}`);

    } catch (err) {
        logger.error(`Operation failed: ${err}`);
        throw err;
    }
}

export function activate(context: vscode.ExtensionContext) {
    logger.info('Directory Digest extension activated.');

    const appendContent = vscode.commands.registerCommand('extension.appendDirectoryContent', async (uri: vscode.Uri) => {
        let targetDir: string | undefined = undefined;
        
        try {
            if (uri) {
                targetDir = uri.fsPath;
            } else {
                const selected = await vscode.window.showOpenDialog({
                    canSelectFolders: true,
                    canSelectMany: false,
                    openLabel: 'Select Directory'
                });
                
                if (!selected || selected.length === 0) {
                    vscode.window.showWarningMessage('No directory selected.');
                    return;
                }
                targetDir = selected[0].fsPath;
            }

            const processWithProgress = async (): Promise<void> => {
                return await vscode.window.withProgress({
                    location: vscode.ProgressLocation.Notification,
                    title: "Directory Digest",
                    cancellable: true
                }, async (progress, token) => {
                    progress.report({ message: "Initializing directory scan..." });
                    
                    const progressContext: ProgressContext = {
                        report: progress.report.bind(progress),
                        token: token
                    };
                    
                    const startTime = Date.now();
                    await appendDirectoryContent(targetDir!, progressContext);
                    const duration = ((Date.now() - startTime) / 1000).toFixed(2);
                    
                    if (!token.isCancellationRequested) {
                        vscode.window.showInformationMessage(
                            `Directory content processed successfully! (${duration}s)`
                        );
                    }
                });
            };

            await processWithProgress();

        } catch (err) {
            logger.error(`Command execution failed: ${err}`);
            const shouldRetry = await showErrorWithRetry('Failed to process directory', err);
            if (shouldRetry && targetDir) {
                // Retry the operation
                try {
                    await vscode.window.withProgress({
                        location: vscode.ProgressLocation.Notification,
                        title: "Directory Digest (Retry)",
                        cancellable: true
                    }, async (progress, token) => {
                        const progressContext: ProgressContext = {
                            report: progress.report.bind(progress),
                            token: token
                        };
                        await appendDirectoryContent(targetDir!, progressContext);
                    });
                    
                    vscode.window.showInformationMessage('Directory processed successfully on retry!');
                } catch (retryErr) {
                    vscode.window.showErrorMessage(`Retry failed: ${retryErr}`);
                }
            }
        }
    });

    const appendToOutputDir = vscode.commands.registerCommand('extension.appendAllToOutputDir', async (uri: vscode.Uri) => {
        let targetDir: string | undefined;
        
        if (uri) {
            targetDir = uri.fsPath;
        } else {
            const selected = await vscode.window.showOpenDialog({
                canSelectFolders: true,
                canSelectMany: false,
                openLabel: 'Select Directory'
            });
            
            if (!selected || selected.length === 0) {
                vscode.window.showWarningMessage('No directory selected.');
                return;
            }
            targetDir = selected[0].fsPath;
        }
        
        const dirName = path.basename(targetDir!);
        
        try {
            const processWithProgress = async (): Promise<void> => {
                return await vscode.window.withProgress({
                    location: vscode.ProgressLocation.Notification,
                    title: "Directory Digest - Concatenate Entirety",
                    cancellable: false
                }, async (progress) => {
                    progress.report({ message: "Concatenating directory contents..." });
                    
                    const startTime = Date.now();
                    await appendAllToOutputDir(targetDir!);
                    const duration = ((Date.now() - startTime) / 1000).toFixed(2);
                    
                    vscode.window.showInformationMessage(
                        `Directory concatenated in .${dirName} successfully! (${duration}s)`
                    );
                });
            };
        
            await processWithProgress();
        
        } catch (err) {
            logger.error(`Command execution failed: ${err}`);
            const shouldRetry = await showErrorWithRetry('Failed to organize directory', err);
            if (shouldRetry) {
                // Retry the operation
                try {
                    await vscode.window.withProgress({
                        location: vscode.ProgressLocation.Notification,
                        title: "Directory Digest - Concatenate Entirety (Retry)",
                        cancellable: false
                    }, async (progress) => {
                        progress.report({ message: "Retrying directory concatenation..." });
                        await appendAllToOutputDir(targetDir!);
                    });
                    
                    vscode.window.showInformationMessage(`Directory concatenated successfully on retry in .${dirName}!`);
                } catch (retryErr) {
                    vscode.window.showErrorMessage(`Retry failed: ${retryErr}`);
                }
            }
        }
    });

    context.subscriptions.push(appendContent, appendToOutputDir);
}

export function deactivate() {
    logger.info('Directory Digest extension deactivated.');
}



Directory: src
File: config.ts
===============
/* src/config.ts */
/**
 * @file Centralized configuration for file and directory exclusion rules.
 * @packageDocumentation
 *
 * @remarks
 * # Directory Digest – Exclusion Configuration Module
 *▫~•◦------------------------------------------------------------‣
 *
 * This module is designed for integration into ArcMoon Code Analysis System to achieve consistent and efficient file system traversal by defining global exclusion rules.
 *
 * ### Key Capabilities
 * - **File Extension Exclusion:** Provides a comprehensive list of file extensions that should be ignored during scans, such as compiled binaries, archives, and temporary files.
 * - **Directory Exclusion:** Defines a set of directory names (e.g., build outputs, version control folders, package manager caches) to be excluded from processing.
 * - **Specific Filename Exclusion:** Lists explicit filenames (like lockfiles or system-generated artifacts) that are to be bypassed by tools.
 *
 * ### Architectural Notes
 * This module centralizes configuration for file system traversal and analysis tools. It is consumed by modules responsible for scanning, indexing, or processing codebases to ensure adherence to a unified exclusion policy. The constant arrays are designed for direct import and immutability.
 *
 * @see {@link CodeScannerModule} for modules consuming these configurations.
 * @see {@link FileSystemIntegrityChecker} for related validation contexts.
 * 
/*▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

export const excludedFileExtensions: string[] = [
  '.env', '.ini', '.cfg', '.config', '.lock',
  '.exe', '.dll', '.so', '.dylib', '.class', '.pyc', '.pyo', '.pyd',
  '.obj', '.o', '.a', '.lib', '.out', '.rlib', '.rmeta',
  '.jar', '.war', '.ear', '.egg', '.wheel', '.whl', '.gem',
  '.ttf', '.otf', '.woff', '.woff2', '.eot',
  '.swp', '.cache', '.tmp', '.temp', '.swo',
  '.bin', '.dat', '.db', '.sqlite', '.sqlite3', '.mdb',
  '.pdb', '.ilk', '.exp', '.map',
  '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',
  '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.ico',
  '.mp3', '.mp4', '.wav', '.avi', '.mov',
  '.zip', '.rar', '.7z', '.tar', '.gz', '.tgz', '.bz2',
  '.iml', '.idea', '.project', '.classpath', '.settings',
  '.vscode', '.vs', '.suo', '.user', '.sln', '.xcodeproj',
  '.xcworkspace', '.DS_Store',
  '.pdf', '.svg', '.webp', '.heic', '.avif',
  '.tsbuildinfo',
  '.lcov', '.gcno', '.gcda',
  '.nupkg', '.rpm', '.deb', '.apk', '.dmg', '.iso', '.msi', '.pkg', '.appimage', '.snap',
  '.ipynb', '.bak', '.orig', '.rej', '.log'
];

export const excludedDirectories: string[] = [
  '0L', '.git', '.svn', '.hg', '.bzr', 'CVS',
  'node_modules', 'target', 'build', 'dist', 'bin', 'obj', 'out',
  '__pycache__', '.pytest_cache', '.tox', '.venv', 'venv', 'env', 'Lib', 'Scripts', 'site-packages',
  'classes', 'META-INF', 'WEB-INF',
  'bower_components', 'jspm_packages', '.npm', '.yarn',
  'vendor/bundle', '.bundle',
  'packages', 'Debug', 'Release', 'x86', 'x64', 'AnyCPU',
  '.idea', '.vscode', '.vs', '.settings', '.project', '.classpath',
  'logs', 'log', 'tmp', 'temp', 'cache', '.cache',
  'docs', 'doc', 'documentation',
  'coverage', '.nyc_output', 'htmlcov',
  '.github', '.gitlab', '.circleci', '.jenkins',
  '.docker',
  '.history', '.grunt', '.sass-cache',
  'public/hot', 'storage', 'compiled', 'uploads', 'vendor',
  '.pnpm', '.pnpm-store', '.yarn/cache', '.yarn/unplugged', '.yarn/releases', '.yarn/plugins',
  '.next', '.nuxt', '.svelte-kit', '.astro', '.docusaurus', '.vite', '.vitepress', '.parcel-cache', '.rollup.cache', '.storybook', 'storybook-static',
  '.gradle', 'gradle', '.mvn', 'Pods', 'DerivedData', '.build', '.swiftpm', 'Carthage/Build', '.cxx',
  'bazel-bin', 'bazel-out', 'bazel-testlogs', 'buck-out', '.buckd',
  '.serverless', '.aws-sam', '.terraform', '.terragrunt-cache', '.pulumi', 'cdk.out',
  '.mypy_cache', '.ruff_cache', '.nox', '.hypothesis', '.ipynb_checkpoints', '.pybuilder',
  '$RECYCLE.BIN', 'System Volume Information', '.Trashes', '.Trash', '.Trash-*', '.Spotlight-V100', '.fseventsd', 'lost+found'
];

export const excludedFileNames: string[] = [
  'Cargo.lock', 'gradle.lockfile', 'package-lock.json', 'pnpm-lock.yaml', 'yarn.lock',
  'composer.lock', 'Gemfile.lock', 'Podfile.lock', 'Package.resolved', 'go.sum', 'Pipfile.lock', 'poetry.lock',
  'Thumbs.db', 'desktop.ini', '.DS_Store',
  'npm-debug.log', 'yarn-error.log', 'lerna-debug.log'
];



Directory: src
File: extension.ts
==================
// src/extension.ts

import * as vscode from 'vscode';
import * as path from 'path';
import * as fsPromises from 'fs/promises';
import { minimatch } from 'minimatch';
import { logger } from './utils/logger.js';
import { excludedFileExtensions, excludedDirectories } from './config.js';

// Configuration interfaces
interface DigestConfig {
    outputFormat: 'Text' | 'Markdown' | 'JSON';
    maxFileSize: number;
    maxDepth: number;
    includePatterns: string[];
    excludePatterns: string[];
    configFilePath: string;
    excludedFileExtensions: string[];
    excludedDirectories: string[];
}

interface ConfigFile {
    includeDirectories?: string[];
    excludeDirectories?: string[];
    includeFiles?: string[];
    excludeFiles?: string[];
    includePatterns?: string[];
    excludePatterns?: string[];
}

interface FileEntry {
    path: string;
    relativePath: string;
    content?: string;
    size: number;
    isDirectory: boolean;
}

interface ProgressContext {
    report: (value: { message?: string; increment?: number }) => void;
    token: vscode.CancellationToken;
}

/**
 * Loads configuration from VS Code settings
 */
function loadConfiguration(): DigestConfig {
    const config = vscode.workspace.getConfiguration('directoryDigest');
    
    return {
        outputFormat: config.get<'Text' | 'Markdown' | 'JSON'>('outputFormat', 'Text'),
        maxFileSize: config.get<number>('maxFileSize', 1048576), // 1MB default
        maxDepth: config.get<number>('maxDepth', 10),
        includePatterns: config.get<string[]>('includePatterns', []),
        excludePatterns: config.get<string[]>('excludePatterns', []),
        configFilePath: config.get<string>('configFilePath', '.ddconfig'),
        excludedFileExtensions: config.get<string[]>('appendContent.excludedFileExtensions', excludedFileExtensions),
        excludedDirectories: config.get<string[]>('appendContent.excludedDirectories', excludedDirectories)
    };
}

/**
 * Loads and parses .ddconfig file if it exists
 */
async function loadConfigFile(baseDir: string, configFileName: string): Promise<ConfigFile | null> {
    const configPath = path.join(baseDir, configFileName);
    
    try {
        const configContent = await fsPromises.readFile(configPath, 'utf-8');
        const configData = JSON.parse(configContent) as ConfigFile;
        logger.info(`Loaded config file: ${configPath}`);
        return configData;
    } catch (err) {
        if ((err as { code?: string }).code !== 'ENOENT') {
            logger.warn(`Failed to load config file ${configPath}: ${err}`);
        }
        return null;
    }
}

/**
 * Shows user-friendly error message with retry option
 */
async function showErrorWithRetry(message: string, error: unknown): Promise<boolean> {
    const errorMsg = error instanceof Error ? error.message : String(error);
    const action = await vscode.window.showErrorMessage(
        `${message}: ${errorMsg}`,
        'Retry',
        'Cancel'
    );
    return action === 'Retry';
}

// Helper functions that were previously not exported
export function sanitizeFilename(filename: string): string {
    const ext = path.extname(filename);
    const basename = path.basename(filename, ext);
    const sanitized = basename.replace(/[^a-zA-Z0-9-]/g, '_');
    return `${sanitized}${ext}`;
}

export function shouldExcludeDirectory(dirName: string, config?: DigestConfig, configFile?: ConfigFile | null): boolean {
    const exclusions = config?.excludedDirectories || excludedDirectories;
    
    // Check config file exclusions
    if (configFile?.excludeDirectories?.includes(dirName)) {
        return true;
    }
    
    return exclusions.some((excl: string) => {
        if (excl.includes('*')) {
            const regex = new RegExp(`^${excl.replace(/\*/g, '.*')}$`);
            return regex.test(dirName);
        }
        return excl === dirName;
    });
}

export function shouldExcludeFile(fileName: string, config?: DigestConfig, configFile?: ConfigFile | null): boolean {
    const fileExt = path.extname(fileName).toLowerCase();
    const exclusions = config?.excludedFileExtensions || excludedFileExtensions;
    
    // Check config file exclusions
    if (configFile?.excludeFiles?.includes(fileName)) {
        return true;
    }
    
    return exclusions.some((excl: string) => {
        if (excl.includes('*')) {
            const regex = new RegExp(`^${excl.replace(/\*/g, '.*')}$`);
            return regex.test(fileExt);
        }
        return fileExt === excl;
    });
}

/**
 * Checks if a file matches the include/exclude patterns
 */
function matchesPatterns(filePath: string, config: DigestConfig, configFile?: ConfigFile | null): boolean {
    const relativePath = filePath;
    
    // Check config file patterns first
    if (configFile?.includePatterns?.length) {
        const matchesInclude = configFile.includePatterns.some(pattern => minimatch(relativePath, pattern));
        if (!matchesInclude) return false;
    }
    
    if (configFile?.excludePatterns?.length) {
        const matchesExclude = configFile.excludePatterns.some(pattern => minimatch(relativePath, pattern));
        if (matchesExclude) return false;
    }
    
    // Check VS Code config patterns
    if (config.includePatterns.length > 0) {
        const matchesInclude = config.includePatterns.some(pattern => minimatch(relativePath, pattern));
        if (!matchesInclude) return false;
    }
    
    if (config.excludePatterns.length > 0) {
        const matchesExclude = config.excludePatterns.some(pattern => minimatch(relativePath, pattern));
        if (matchesExclude) return false;
    }
    
    return true;
}

/**
 * Checks if file size is within limits
 */
async function isFileSizeAllowed(filePath: string, maxFileSize: number): Promise<boolean> {
    try {
        const stats = await fsPromises.stat(filePath);
        return stats.size <= maxFileSize;
    } catch (err) {
        logger.warn(`Failed to check file size for ${filePath}: ${err}`);
        return false;
    }
}

export function isTextFile(filePath: string): boolean {
    const textFileExtensions = [
        '.txt', '.md', '.js', '.ts', '.json', '.html', '.css', '.py', '.java', '.c', '.cpp',
        '.rs', '.go', '.rb', '.php', '.sql', '.xml', '.yaml', '.yml', '.toml', '.ini'
    ];
    return textFileExtensions.includes(path.extname(filePath).toLowerCase());
}

/**
 * Formats file entry content based on the specified output format
 */
function formatFileEntry(entry: FileEntry, format: 'Text' | 'Markdown' | 'JSON'): string {
    switch (format) {
        case 'Markdown':
            if (entry.isDirectory) {
                return `## Directory: ${entry.relativePath}\n\n`;
            } else {
                const extension = path.extname(entry.path).slice(1) || 'text';
                return `### File: ${entry.relativePath}\n\n\`\`\`${extension}\n${entry.content || ''}\n\`\`\`\n\n`;
            }
        
        case 'JSON':
            return JSON.stringify(entry, null, 2) + '\n';
        
        case 'Text':
        default:
            if (entry.isDirectory) {
                return `\nDirectory: ${entry.relativePath}\n${'='.repeat(entry.relativePath.length + 11)}\n\n`;
            } else {
                const header = `\nFile: ${entry.relativePath}\n${'='.repeat(entry.relativePath.length + 6)}\n`;
                return header + (entry.content || '') + '\n\n';
            }
    }
}

/**
 * Gets the appropriate file extension for the output format
 */
function getOutputExtension(format: 'Text' | 'Markdown' | 'JSON'): string {
    switch (format) {
        case 'Markdown': return '.md';
        case 'JSON': return '.json';
        case 'Text':
        default: return '.txt';
    }
}

/**
 * Wraps JSON output with proper structure
 */
function wrapJSONOutput(entries: FileEntry[], dirName: string): string {
    const output = {
        directory: dirName,
        generated: new Date().toISOString(),
        entries: entries
    };
    return JSON.stringify(output, null, 2);
}

/**
 * Creates a single file containing all directory contents with enhanced configuration support
 */
export async function appendDirectoryContent(selectedDir: string, progressContext?: ProgressContext): Promise<void> {
    const config = loadConfiguration();
    const configFile = await loadConfigFile(selectedDir, config.configFilePath);
    const dirName = path.basename(selectedDir);
    const outputExtension = getOutputExtension(config.outputFormat);
    
    // Create dot-prefixed directory for output
    const dotDirName = `.${sanitizeFilename(dirName)}Files`;
    const outputDir = path.join(selectedDir, dotDirName);
    const outputFile = path.join(outputDir, `${sanitizeFilename(dirName)}${outputExtension}`);
    
    const entries: FileEntry[] = [];
    let processedFiles = 0;
    let totalFiles = 0;

    // Check if path exists and is a directory
    let dirExists = false;
    try {
        const stats = await fsPromises.stat(selectedDir);
        dirExists = stats.isDirectory();
    } catch (err: unknown) {
        if ((err as { code?: string }).code !== 'ENOENT') {
            throw err;
        }
        // For ENOENT, dirExists remains false
    }

    if (!dirExists) {
        // Create empty output for non-existent directory
        await fsPromises.mkdir(outputDir, { recursive: true });
        logger.info(`Created output directory for non-existent directory: ${outputDir}`);
        
        const outputContent = '';
        
        await fsPromises.writeFile(outputFile, outputContent, 'utf-8');
        logger.info(`Created empty digest for non-existent directory: ${outputFile}`);
        
        progressContext?.report({ message: 'Created empty digest for non-existent directory' });
        return;
    }

    // First pass: count total files for progress tracking
    async function countFiles(dir: string, depth: number = 0): Promise<number> {
        if (depth >= config.maxDepth) {
            return 0;
        }

        try {
            const dirEntries = await fsPromises.readdir(dir, { withFileTypes: true });
            let count = 0;

            for (const entry of dirEntries) {
                const fullPath = path.join(dir, entry.name);
                const relativePath = path.relative(selectedDir, fullPath);

                if (entry.isSymbolicLink()) {
                    continue;
                }

                if (entry.isDirectory()) {
                    if (!shouldExcludeDirectory(entry.name, config, configFile ?? undefined)) {
                        count += await countFiles(fullPath, depth + 1);
                    }
                } else if (entry.isFile()) {
                    if (!shouldExcludeFile(entry.name, config, configFile ?? undefined) &&
                        matchesPatterns(relativePath, config, configFile ?? undefined) &&
                        await isFileSizeAllowed(fullPath, config.maxFileSize)) {
                        count++;
                    }
                }
            }
            return count;
        } catch (err) {
            logger.error(`Failed to count files in directory ${dir}: ${err}`);
            return 0;
        }
    }

    async function processFile(filePath: string): Promise<void> {
        try {
            const relativePath = path.relative(selectedDir, filePath);
            
            if (!await isFileSizeAllowed(filePath, config.maxFileSize)) {
                logger.warn(`File ${filePath} exceeds size limit (${config.maxFileSize} bytes)`);
                return;
            }

            if (!matchesPatterns(relativePath, config, configFile ?? undefined)) {
                return;
            }

            let content = '';
            if (isTextFile(filePath)) {
                try {
                    content = await fsPromises.readFile(filePath, 'utf-8');
                } catch (err) {
                    logger.error(`Failed to read file content ${filePath}: ${err}`);
                    content = `[Error reading file: ${err}]`;
                }
            }

            const stats = await fsPromises.stat(filePath);
            const entry: FileEntry = {
                path: filePath,
                relativePath,
                content,
                size: stats.size,
                isDirectory: false
            };

            entries.push(entry);
            processedFiles++;
            
            const progressPercent = (processedFiles / totalFiles) * 100;
            progressContext?.report({
                message: `Processed ${processedFiles}/${totalFiles} files (${progressPercent.toFixed(1)}%)`,
                increment: (1 / totalFiles) * 100
            });
            
            logger.info(`Processed file: ${filePath}`);
        } catch (err) {
            logger.error(`Failed to process file ${filePath}: ${err}`);
        }
    }

    async function processDirectory(dir: string, depth: number = 0): Promise<void> {
        if (depth >= config.maxDepth) {
            logger.warn(`Maximum depth (${config.maxDepth}) reached at: ${dir}`);
            return;
        }

        try {
            const dirEntries = await fsPromises.readdir(dir, { withFileTypes: true });
            const processPromises = dirEntries.map(async (entry) => {
                if (progressContext?.token.isCancellationRequested) {
                    throw new Error('Operation was cancelled by user');
                }

                const fullPath = path.join(dir, entry.name);
                if (entry.isSymbolicLink()) {
                    return;
                }
                
                if (entry.isDirectory() && !shouldExcludeDirectory(entry.name, config, configFile)) {
                    await processDirectory(fullPath, depth + 1);
                } else if (entry.isFile() && !shouldExcludeFile(entry.name, config, configFile)) {
                    await processFile(fullPath);
                }
            });
            await Promise.all(processPromises);
        } catch (err) {
            if (err instanceof Error && err.message.includes('cancelled')) {
                throw err;
            }
            logger.error(`Failed to process directory ${dir}: ${err}`);
        }
    }

    try {
        // First pass: count total files for progress tracking
        totalFiles = await countFiles(selectedDir);
        progressContext?.report({ message: `Processing ${totalFiles} files...` });

        await processDirectory(selectedDir);

        // Now create output directory and write
        await fsPromises.mkdir(outputDir, { recursive: true });
        logger.info(`Created output directory: ${outputDir}`);

        // Write output based on format
        let outputContent = '';
        if (config.outputFormat === 'JSON') {
            outputContent = wrapJSONOutput(entries, dirName);
        } else {
            entries.forEach(entry => {
                outputContent += formatFileEntry(entry, config.outputFormat);
            });
        }

        await fsPromises.writeFile(outputFile, outputContent, 'utf-8');
        progressContext?.report({ message: 'Writing output file...', increment: 0 });
        
        logger.info(`Successfully processed ${processedFiles} files and created: ${outputFile}`);

    } catch (err) {
        logger.error(`Failed to process directory: ${err}`);
        throw err;
    }
}

/**
 * Concatenates all files into organized structure in .{dirName} directory
 */
export async function appendAllToOutputDir(selectedDir: string): Promise<void> {
    const dirName = path.basename(selectedDir);
    const outputDir = path.join(selectedDir, `.${sanitizeFilename(dirName)}`);
    const treeFile = path.join(outputDir, `${sanitizeFilename(dirName)}.txt`);

    try {
        await fsPromises.mkdir(outputDir, { recursive: true });
        await fsPromises.writeFile(treeFile, '');
        logger.info(`Created output directory: ${outputDir}`);

        async function processFile(dir: string, filePath: string): Promise<void> {
            try {
                const relativeDir = path.relative(selectedDir, dir) || dirName;
                const parentName = sanitizeFilename(path.basename(dir));
                const outputFile = path.join(outputDir, `${parentName}.txt`);

                if (isTextFile(filePath)) {
                    const content = await fsPromises.readFile(filePath, 'utf-8');
                    const header = `\nDirectory: ${relativeDir}\nFile: ${path.basename(filePath)}\n${'='.repeat(path.basename(filePath).length + 6)}\n`;
                    await fsPromises.appendFile(outputFile, header + content + '\n\n');
                    await fsPromises.appendFile(treeFile, header + content + '\n\n');
                    logger.info(`Processed text file: ${filePath}`);
                } else {
                    const header = `\n[${path.basename(filePath)}]binary\n${'='.repeat(path.basename(filePath).length + 8)}\n`;
                    await fsPromises.appendFile(outputFile, header);
                    await fsPromises.appendFile(treeFile, header);
                    logger.info(`Processed binary file: ${filePath}`);
                }
            } catch (err) {
                logger.error(`Failed to process file ${filePath}: ${err}`);
            }
        }

        async function processDirectory(dir: string, depth: number = 0): Promise<void> {
            if (depth > 10) {
                logger.warn(`Maximum depth reached at: ${dir}`);
                return;
            }

            try {
                const entries = await fsPromises.readdir(dir, { withFileTypes: true });
                const processPromises = entries.map(async (entry) => {
                    const fullPath = path.join(dir, entry.name);
                    if (entry.isSymbolicLink()) {
                        return;
                    }
                    if (entry.isDirectory() && !shouldExcludeDirectory(entry.name)) {
                        await processDirectory(fullPath, depth + 1);
                    } else if (entry.isFile() && !shouldExcludeFile(entry.name)) {
                        await processFile(dir, fullPath);
                    }
                });
                await Promise.all(processPromises);
            } catch (err) {
                logger.error(`Failed to process directory ${dir}: ${err}`);
            }
        }

        await processDirectory(selectedDir);

        // Clean up empty files
        const files = await fsPromises.readdir(outputDir);
        await Promise.all(files.map(async (file) => {
            const filePath = path.join(outputDir, file);
            const stat = await fsPromises.stat(filePath);
            if (stat.size === 0) {
                await fsPromises.unlink(filePath);
                logger.info(`Removed empty file: ${filePath}`);
            }
        }));

        logger.info(`Successfully processed directory: ${selectedDir}`);

    } catch (err) {
        logger.error(`Operation failed: ${err}`);
        throw err;
    }
}

export function activate(context: vscode.ExtensionContext) {
    logger.info('Directory Digest extension activated.');

    const appendContent = vscode.commands.registerCommand('extension.appendDirectoryContent', async (uri: vscode.Uri) => {
        let targetDir: string | undefined = undefined;
        
        try {
            if (uri) {
                targetDir = uri.fsPath;
            } else {
                const selected = await vscode.window.showOpenDialog({
                    canSelectFolders: true,
                    canSelectMany: false,
                    openLabel: 'Select Directory'
                });
                
                if (!selected || selected.length === 0) {
                    vscode.window.showWarningMessage('No directory selected.');
                    return;
                }
                targetDir = selected[0].fsPath;
            }

            const processWithProgress = async (): Promise<void> => {
                return await vscode.window.withProgress({
                    location: vscode.ProgressLocation.Notification,
                    title: "Directory Digest",
                    cancellable: true
                }, async (progress, token) => {
                    progress.report({ message: "Initializing directory scan..." });
                    
                    const progressContext: ProgressContext = {
                        report: progress.report.bind(progress),
                        token: token
                    };
                    
                    const startTime = Date.now();
                    await appendDirectoryContent(targetDir!, progressContext);
                    const duration = ((Date.now() - startTime) / 1000).toFixed(2);
                    
                    if (!token.isCancellationRequested) {
                        vscode.window.showInformationMessage(
                            `Directory content processed successfully! (${duration}s)`
                        );
                    }
                });
            };

            await processWithProgress();

        } catch (err) {
            logger.error(`Command execution failed: ${err}`);
            const shouldRetry = await showErrorWithRetry('Failed to process directory', err);
            if (shouldRetry && targetDir) {
                // Retry the operation
                try {
                    await vscode.window.withProgress({
                        location: vscode.ProgressLocation.Notification,
                        title: "Directory Digest (Retry)",
                        cancellable: true
                    }, async (progress, token) => {
                        const progressContext: ProgressContext = {
                            report: progress.report.bind(progress),
                            token: token
                        };
                        await appendDirectoryContent(targetDir!, progressContext);
                    });
                    
                    vscode.window.showInformationMessage('Directory processed successfully on retry!');
                } catch (retryErr) {
                    vscode.window.showErrorMessage(`Retry failed: ${retryErr}`);
                }
            }
        }
    });

    const appendToOutputDir = vscode.commands.registerCommand('extension.appendAllToOutputDir', async (uri: vscode.Uri) => {
        let targetDir: string | undefined;
        
        if (uri) {
            targetDir = uri.fsPath;
        } else {
            const selected = await vscode.window.showOpenDialog({
                canSelectFolders: true,
                canSelectMany: false,
                openLabel: 'Select Directory'
            });
            
            if (!selected || selected.length === 0) {
                vscode.window.showWarningMessage('No directory selected.');
                return;
            }
            targetDir = selected[0].fsPath;
        }
        
        const dirName = path.basename(targetDir!);
        
        try {
            const processWithProgress = async (): Promise<void> => {
                return await vscode.window.withProgress({
                    location: vscode.ProgressLocation.Notification,
                    title: "Directory Digest - Concatenate Entirety",
                    cancellable: false
                }, async (progress) => {
                    progress.report({ message: "Concatenating directory contents..." });
                    
                    const startTime = Date.now();
                    await appendAllToOutputDir(targetDir!);
                    const duration = ((Date.now() - startTime) / 1000).toFixed(2);
                    
                    vscode.window.showInformationMessage(
                        `Directory concatenated in .${dirName} successfully! (${duration}s)`
                    );
                });
            };
        
            await processWithProgress();
        
        } catch (err) {
            logger.error(`Command execution failed: ${err}`);
            const shouldRetry = await showErrorWithRetry('Failed to organize directory', err);
            if (shouldRetry) {
                // Retry the operation
                try {
                    await vscode.window.withProgress({
                        location: vscode.ProgressLocation.Notification,
                        title: "Directory Digest - Concatenate Entirety (Retry)",
                        cancellable: false
                    }, async (progress) => {
                        progress.report({ message: "Retrying directory concatenation..." });
                        await appendAllToOutputDir(targetDir!);
                    });
                    
                    vscode.window.showInformationMessage(`Directory concatenated successfully on retry in .${dirName}!`);
                } catch (retryErr) {
                    vscode.window.showErrorMessage(`Retry failed: ${retryErr}`);
                }
            }
        }
    });

    context.subscriptions.push(appendContent, appendToOutputDir);
}

export function deactivate() {
    logger.info('Directory Digest extension deactivated.');
}



Directory: .src
File: src.txt
=============



Directory: utils
File: logger.ts
===============
// src/utils/logger.ts
import winston from 'winston';

export const logger = winston.createLogger({
    level: 'info',
    format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.printf((info: winston.Logform.TransformableInfo) => 
            `${info.timestamp} [${info.level.toUpperCase()}]: ${info.message}`
        )
    ),
    transports: [
        new winston.transports.File({ filename: 'extension.log' }),
        new winston.transports.Console()
    ]
});


Directory: test
File: runTest.ts
================
import * as path from 'path';
import * as fs from 'fs';
import { runTests } from '@vscode/test-electron';
async function main() {
    try {
        // The folder containing the Extension Manifest package.json
        const extensionDevelopmentPath = path.resolve(__dirname, '../../../');

        // The path to the extension test script
        const extensionTestsPath = path.resolve(__dirname, './suite/index');
        // The path to test workspace
        const testWorkspace = path.resolve(extensionDevelopmentPath, 'test-fixtures');

        // Download VS Code, unzip it and run the integration test
        await runTests({
            extensionDevelopmentPath,
            extensionTestsPath,
            launchArgs: [testWorkspace]
        });
    } catch (err) {
        console.error('Failed to run tests:', err);
        process.exit(1);
    } finally {
        const testDir = '.vscode-test';
        if (fs.existsSync(testDir)) {
            fs.rmSync(testDir, { recursive: true, force: true });
            console.log(`Cleaned up ${testDir}`);
        }
    }
}

main();


Directory: test\suite
File: extension.test.ts
=======================
/* src/test/suite/extension.test.ts */
/**
 * @file Provides a comprehensive test suite for the Directory Digest VS Code extension.
 * @packageDocumentation
 *
 * @remarks
 * # Directory Digest – Extension Test Suite Module
 *▫~•◦------------------------------------------------‣
 *
 * This module integrates into the VS Code extension test runner to achieve rigorous validation
 * of the Directory Digest extension's core features and reliability.
 *
 * ### Key Capabilities
 * - **Command Verification:** Ensures that all extension commands are correctly registered and available in the VS Code environment.
 * - **Core Functionality Testing:** Validates the two main features: `appendDirectoryContent` (single-file digest) and `appendAllToOutputDir` (structured output).
 * - **Edge Case and Error Handling:** Tests behavior with special file paths, empty directories, file/directory exclusions, and system-level errors like permissions.
 *
 * ### Architectural Notes
 * This test suite utilizes the `vscode` API for integration testing and Node.js's `assert` and `fs`
 * modules for validation. It is designed to work with the main `extension.ts` module.
 *
 * @see {@link ../../extension.ts} for the implementation being tested.
 *
 *▫~•◦------------------------------------------------------------------------------------‣
 * © 2025 ArcMoon Studios ◦ SPDX-License-Identifier MIT OR Apache-2.0 ◦ Author: Lord Xyn ✶
 *///•------------------------------------------------------------------------------------‣

import * as path from 'path';
import * as assert from 'assert';
import * as vscode from 'vscode';
import * as fs from 'fs/promises';
import {
    appendDirectoryContent, appendAllToOutputDir, sanitizeFilename,
    shouldExcludeDirectory, shouldExcludeFile, isTextFile
} from '../../extension.js';
import { excludedFileExtensions, excludedDirectories } from '../../config.js';

interface FileSystemError extends Error {
    code?: string;
}

suite('Directory Digest Extension Test Suite', () => {
    const testFixturesDir = path.join(__dirname, '..', '..', 'test-fixtures');
    const directoryTestDir = path.join(testFixturesDir, 'directory-test');
    const recursiveTestDir = path.join(testFixturesDir, 'recursive-test');
    const excludeTestDir = path.join(testFixturesDir, 'exclude-test');
    const specialCharsDir = path.join(testFixturesDir, 'special-chars-test');

    suiteSetup(async () => {
        try {
            console.log('Test setup starting...');
            console.log('Available extensions:', vscode.extensions.all.map(e => e.id));

            const extensionId = 'ArcMoon Studios.directory-digest';
            console.log('Looking for extension:', extensionId);

            const ext = vscode.extensions.getExtension(extensionId);
            console.log('Extension found:', ext ? 'yes' : 'no');

            if (!ext) {
                throw new Error(`Extension ${extensionId} not found. Available extensions: ${vscode.extensions.all.map(e => e.id).join(', ')}`);
            }

            console.log('Activating extension...');
            await ext.activate();
            console.log('Extension activated successfully');

            // Give VS Code a moment to register commands
            await new Promise(resolve => setTimeout(resolve, 1000));

            console.log('Setting up test environment...');
            await setupTestEnvironment();
            console.log('Test setup completed successfully');
        } catch (error) {
            console.error('Failed to setup test suite:', error);
            throw error;
        }
    });

    suiteTeardown(async () => {
        await cleanupTestDirectories();
    });

    /**
     * Helper function to create test files and directories
     */
    async function createTestFile(dirPath: string, fileName: string, content: string): Promise<void> {
        await fs.mkdir(dirPath, { recursive: true });
        await fs.writeFile(path.join(dirPath, fileName), content);
    }

    /**
     * Helper function to create test environment
     */
    async function setupTestEnvironment(): Promise<void> {
        // Create base test directories
        await Promise.all([
            fs.mkdir(directoryTestDir, { recursive: true }),
            fs.mkdir(recursiveTestDir, { recursive: true }),
            fs.mkdir(excludeTestDir, { recursive: true }),
            fs.mkdir(specialCharsDir, { recursive: true })
        ]);

        // Setup directory test files
        await createTestFile(directoryTestDir, 'test1.txt', 'Test content 1');
        await createTestFile(directoryTestDir, 'test2.txt', 'Test content 2');
        await createTestFile(directoryTestDir, 'test.exe', 'Binary content');
        await createTestFile(path.join(directoryTestDir, 'subfolder'), 'subtest.txt', 'Subfolder content');

        // Setup exclude test files
        await createTestFile(excludeTestDir, 'include.txt', 'Include this content');
        await createTestFile(excludeTestDir, 'exclude.exe', 'Exclude this content');
        await createTestFile(excludeTestDir, '.env', 'SECRET=test');
        await createTestFile(path.join(excludeTestDir, 'node_modules'), 'should_not_process.txt', 'Should not process');

        // Setup recursive test structure
        let currentDir = recursiveTestDir;
        for (let i = 0; i < 5; i++) {
            currentDir = path.join(currentDir, `level-${i}`);
            await createTestFile(currentDir, 'test.txt', `Level ${i} test content`);
            await createTestFile(currentDir, `extra${i}.txt`, `Extra content ${i}`);
        }

        // Setup special characters test
        const specialDir = path.join(specialCharsDir, 'special@#$chars');
        await createTestFile(specialDir, 'test.txt', 'Special characters test');
        await createTestFile(specialDir, 'test2@#.txt', 'More special characters');
        await createTestFile(path.join(specialDir, 'sub@folder'), 'sub@test.txt', 'Special subfolder content');
    }

    /**
     * Helper function to clean up test directories
     */
    async function cleanupTestDirectories(): Promise<void> {
        const dirs = [directoryTestDir, recursiveTestDir, excludeTestDir, specialCharsDir];
        for (const dir of dirs) {
            try {
                await fs.rm(dir, { recursive: true, force: true });
            } catch (err) {
                const fsError = err as FileSystemError;
                if (fsError.code !== 'ENOENT') {
                    throw err;
                }
            }
        }
    }

    suite('Command Registration Tests', () => {
        test('commands should be registered', async () => {
            const commands = await vscode.commands.getCommands(true);
            console.log('Available commands:', commands); // For debugging

            const expectedCommands = [
                'extension.appendDirectoryContent',
                'extension.appendAllToOutputDir'
            ];

            for (const cmd of expectedCommands) {
                assert.strictEqual(
                    commands.includes(cmd),
                    true,
                    `Command "${cmd}" not found in available commands: ${commands.join(', ')}`
                );
            }
        });
    });

    suite('Append Directory Content Tests', () => {
        test('should create a single file with directory contents', async () => {
            await appendDirectoryContent(directoryTestDir);

            const dotDir = '.directory-testFiles';
            const outputFile = path.join(directoryTestDir, dotDir, 'directory-test.txt');
            const exists = await fs.access(outputFile).then(() => true).catch(() => false);
            assert.strictEqual(exists, true, 'Output file should be created');

            const content = await fs.readFile(outputFile, 'utf8');
            assert.ok(content.includes('Test content 1'), 'Should contain content from first file');
            assert.ok(content.includes('Test content 2'), 'Should contain content from second file');
            assert.ok(content.includes('Subfolder content'), 'Should contain subfolder content');
            assert.ok(!content.includes('Binary content'), 'Should not contain binary file content');
            assert.ok(content.includes('File: test1.txt'), 'Should have header for test1.txt');
            assert.ok(content.includes('File: test2.txt'), 'Should have header for test2.txt');
            assert.ok(content.includes('File: subfolder\\subtest.txt'), 'Should have header for subtest.txt');
            assert.ok(!content.includes('File: test.exe'), 'Should not have header for binary file');
        });

        test('should handle file exclusions correctly', async () => {
            await appendDirectoryContent(excludeTestDir);

            const dotDir = '.exclude-testFiles';
            const outputFile = path.join(excludeTestDir, dotDir, 'exclude-test.txt');
            const content = await fs.readFile(outputFile, 'utf8');

            assert.ok(content.includes('Include this content'), 'Should include non-excluded content');
            assert.ok(!content.includes('Exclude this content'), 'Should not include excluded content');
            assert.ok(!content.includes('SECRET=test'), 'Should not include env file content');
            assert.ok(!content.includes('Should not process'), 'Should not include content from excluded directories');
        });

        test('should preserve directory structure information', async () => {
            await appendDirectoryContent(recursiveTestDir);

            const dotDir = '.recursive-testFiles';
            const outputFile = path.join(recursiveTestDir, dotDir, 'recursive-test.txt');
            const content = await fs.readFile(outputFile, 'utf8');

            for (let i = 0; i < 5; i++) {
                assert.ok(content.includes(`Level ${i} test content`), `Should contain content from level ${i}`);
                assert.ok(content.includes(`level-${i}`), `Should contain directory path for level ${i}`);
                assert.ok(content.includes(`Extra content ${i}`), `Should contain extra content from level ${i}`);
            }
            assert.ok(content.includes('File: level-0\\test.txt'), 'Should have header for level-0/test.txt');
            assert.ok(content.includes('File: level-0\\level-1\\test.txt'), 'Should have header for nested level-1/test.txt');
            assert.ok(content.includes('File: level-0\\level-1\\level-2\\level-3\\level-4\\test.txt'), 'Should have header for deepest level-4/test.txt');
        });

        test('should handle special characters in filenames and paths', async () => {
            await appendDirectoryContent(specialCharsDir);

            const dotDir = '.special-chars-testFiles';
            const outputFile = path.join(specialCharsDir, dotDir, 'special-chars-test.txt');
            const exists = await fs.access(outputFile).then(() => true).catch(() => false);
            assert.strictEqual(exists, true, 'Sanitized output file should exist');

            const content = await fs.readFile(outputFile, 'utf8');
            assert.ok(content.includes('Special characters test'), 'Should contain main content');
            assert.ok(content.includes('More special characters'), 'Should contain content from special character files');
            assert.ok(content.includes('Special subfolder content'), 'Should contain content from special character subfolders');
        });
    });

    suite('Append All To Output Directory Tests', () => {
        test('should create organized structure in output directory', async () => {
            await appendAllToOutputDir(recursiveTestDir);

            const dirName = 'recursive-test';
            const outputDir = path.join(recursiveTestDir, `.${dirName}`);
            const treeFile = path.join(outputDir, `${dirName}.txt`);

            const outputExists = await fs.access(outputDir).then(() => true).catch(() => false);
            const treeExists = await fs.access(treeFile).then(() => true).catch(() => false);

            assert.strictEqual(outputExists, true, 'Output directory should exist');
            assert.strictEqual(treeExists, true, 'Tree file should exist');

            const treeContent = await fs.readFile(treeFile, 'utf8');
            for (let i = 0; i < 5; i++) {
                assert.ok(treeContent.includes(`Level ${i} test content`), `Should contain content from level ${i}`);
                assert.ok(treeContent.includes(`Extra content ${i}`), `Should contain extra content from level ${i}`);
            }

            for (let i = 0; i < 5; i++) {
                const levelFile = path.join(outputDir, `level-${i}.txt`);
                const exists = await fs.access(levelFile).then(() => true).catch(() => false);
                assert.strictEqual(exists, true, `Level ${i} file should exist`);

                const content = await fs.readFile(levelFile, 'utf8');
                assert.ok(content.includes(`Level ${i} test content`), `Level file should contain its content`);
            }
        });

        test('should handle empty directories', async () => {
            const emptyDir = path.join(recursiveTestDir, 'empty-dir');
            await fs.mkdir(emptyDir, { recursive: true });

            await appendAllToOutputDir(recursiveTestDir);

            const dirName = 'recursive-test';
            const outputDir = path.join(recursiveTestDir, `.${dirName}`);
            const emptyDirOutput = path.join(outputDir, 'empty-dir.txt');

            const exists = await fs.access(emptyDirOutput).then(() => true).catch(() => false);
            assert.strictEqual(exists, false, 'Empty directory file should not be created');
        });

        test('should handle file exclusions in output directory', async () => {
            await appendAllToOutputDir(excludeTestDir);

            const dirName = 'exclude-test';
            const outputDir = path.join(excludeTestDir, `.${dirName}`);
            const treeFile = path.join(outputDir, `${dirName}.txt`);
            const content = await fs.readFile(treeFile, 'utf8');

            assert.ok(content.includes('Include this content'), 'Should include non-excluded content');
            assert.ok(!content.includes('Exclude this content'), 'Should not include excluded content');
            assert.ok(!content.includes('SECRET=test'), 'Should not include env file content');
            assert.ok(!content.includes('Should not process'), 'Should not include content from excluded directories');
        });

        test('should handle special characters in output directory', async () => {
            await appendAllToOutputDir(specialCharsDir);

            const dirName = 'special-chars-test';
            const outputDir = path.join(specialCharsDir, `.${dirName}`);
            const treeFile = path.join(outputDir, `${dirName}.txt`);
            const dirContent = await fs.readdir(outputDir);

            const treeContent = await fs.readFile(treeFile, 'utf8');
            assert.ok(treeContent.includes('Special characters test'), 'Tree should contain special characters content');
            assert.ok(treeContent.includes('More special characters'), 'Tree should contain additional special content');
            assert.ok(treeContent.includes('Special subfolder content'), 'Tree should contain subfolder content');

            const sanitizedFiles = dirContent.filter(f => f !== `${dirName}.txt`);
            assert.ok(sanitizedFiles.every(f => /^[a-zA-Z0-9-_]+\.txt$/.test(f)), 'All files should have sanitized names');

            let foundContent = false;
            for (const file of sanitizedFiles) {
                const content = await fs.readFile(path.join(outputDir, file), 'utf8');
                if (content.includes('Special characters test')) {
                    foundContent = true;
                    break;
                }
            }
            assert.ok(foundContent, 'Special characters content should be preserved in sanitized files');
        });

        test('should handle maximum directory depth', async () => {
            let currentDir = recursiveTestDir;
            for (let i = 0; i < 15; i++) {
                currentDir = path.join(currentDir, `deep-${i}`);
                await createTestFile(currentDir, 'test.txt', `Deep level ${i} content`);
            }

            await appendAllToOutputDir(recursiveTestDir);

            const dirName = 'recursive-test';
            const outputDir = path.join(recursiveTestDir, `.${dirName}`);
            const treeFile = path.join(outputDir, `${dirName}.txt`);
            const treeContent = await fs.readFile(treeFile, 'utf8');

            for (let i = 0; i < 10; i++) {
                assert.ok(
                    treeContent.includes(`Deep level ${i} content`),
                    `Should contain content from depth ${i}`
                );
            }

            for (let i = 11; i < 15; i++) {
                assert.ok(
                    !treeContent.includes(`Deep level ${i} content`),
                    `Should not contain content from depth ${i}`
                );
            }
        });
    });

    suite('Error Handling Tests', () => {
        test('should handle non-existent directory gracefully', async () => {
            const nonExistentDir = path.join(testFixturesDir, 'non-existent-dir');
            // Ensure directory doesn't exist
            await fs.rm(nonExistentDir, { recursive: true, force: true }).catch(() => { });
            await appendDirectoryContent(nonExistentDir);

            const dotDir = '.non-existent-dirFiles';
            const outputFile = path.join(nonExistentDir, dotDir, 'non-existent-dir.txt');
            const exists = await fs.access(outputFile).then(() => true).catch(() => false);
            assert.strictEqual(exists, true, 'Output file should be created for non-existent directory');
            const content = await fs.readFile(outputFile, 'utf8');
            assert.strictEqual(content.trim(), '', 'Content should be empty for non-existent directory');
        });

        test('should handle permission errors gracefully', async () => {
            const protectedDir = path.join(testFixturesDir, 'protected-dir');
            await fs.mkdir(protectedDir, { recursive: true });
            await fs.chmod(protectedDir, 0o000);

            try {
                await appendDirectoryContent(protectedDir);
                assert.fail('Expected error for permission denied');
            } catch (err) {
                assert.ok(err instanceof Error, 'Should throw an error for permission denied');
            } finally {
                await fs.chmod(protectedDir, 0o755);
                await fs.rm(protectedDir, { recursive: true, force: true });
            }
        });
    });

    suite('Helper Functions Tests', () => {
        test('sanitizeFilename should replace invalid characters', () => {
            const result = sanitizeFilename('test file@#$.txt');
            assert.strictEqual(result, 'test_file___.txt', 'Should sanitize filename correctly');
        });

        test('sanitizeFilename should handle filenames without extension', () => {
            const result = sanitizeFilename('test@#file');
            assert.strictEqual(result, 'test__file', 'Should sanitize filename without extension');
        });

        test('shouldExcludeDirectory should exclude default directories', () => {
            assert.strictEqual(shouldExcludeDirectory('node_modules'), true, 'Should exclude node_modules');
            assert.strictEqual(shouldExcludeDirectory('.git'), true, 'Should exclude .git');
            assert.strictEqual(shouldExcludeDirectory('src'), false, 'Should not exclude src');
        });

        test('shouldExcludeDirectory should use custom config', () => {
            const mockConfig = { excludedDirectories: ['custom/test'] } as any;
            assert.strictEqual(shouldExcludeDirectory('custom/test', mockConfig), true, 'Should use custom excluded directories');
        });

        test('shouldExcludeFile should exclude default extensions', () => {
            assert.strictEqual(shouldExcludeFile('test.exe'), true, 'Should exclude .exe');
            assert.strictEqual(shouldExcludeFile('test.pdf'), true, 'Should exclude .pdf');
            assert.strictEqual(shouldExcludeFile('test.txt'), false, 'Should not exclude .txt');
        });

        test('shouldExcludeFile should handle custom config', () => {
            const mockConfig = { excludedFileExtensions: ['.custom'] } as any;
            assert.strictEqual(shouldExcludeFile('test.custom', mockConfig), true, 'Should exclude custom extension');
        });

        test('isTextFile should identify text files correctly', () => {
            assert.strictEqual(isTextFile('test.txt'), true, 'Should identify .txt as text');
            assert.strictEqual(isTextFile('test.js'), true, 'Should identify .js as text');
            assert.strictEqual(isTextFile('test.exe'), false, 'Should not identify .exe as text');
            assert.strictEqual(isTextFile('test.png'), false, 'Should not identify .png as text');
        });

        test('appendDirectoryContent should handle config file loading', async () => {
            const testDir = path.join(testFixturesDir, 'config-test');
            await fs.mkdir(testDir, { recursive: true });
            await createTestFile(testDir, 'include.txt', 'Config test content');

            const configPath = path.join(testDir, '.ddconfig');
            const mockConfig = { includeFiles: ['include.txt'], excludeFiles: [] };
            await fs.writeFile(configPath, JSON.stringify(mockConfig));

            await appendDirectoryContent(testDir);

            const dotDir = '.config-testFiles';
            const outputFile = path.join(testDir, dotDir, 'config-test.txt');
            const exists = await fs.access(outputFile).then(() => true).catch(() => false);
            assert.strictEqual(exists, true, 'Output file should exist with config');
            await fs.rm(testDir, { recursive: true, force: true });
        });

        test('appendDirectoryContent should respect max file size', async () => {
            const testDir = path.join(testFixturesDir, 'size-test');
            await fs.mkdir(testDir, { recursive: true });

            // Create a large file >1MB default
            const largeContent = 'a'.repeat(2000000);
            await createTestFile(testDir, 'large.txt', largeContent);
            await createTestFile(testDir, 'small.txt', 'small content');

            // Temporarily override config if possible, but since it's loaded internally, test via output
            await appendDirectoryContent(testDir);

            const dotDir = '.size-testFiles';
            const outputFile = path.join(testDir, dotDir, 'size-test.txt');
            const content = await fs.readFile(outputFile, 'utf8');
            assert.ok(content.includes('small content'), 'Should include small file');
            // Large file should be skipped, but since no direct check, assume based on logic

            await fs.rm(testDir, { recursive: true, force: true });
        });

        test('excludedDirectories should contain expected default exclusions', () => {
            assert.ok(excludedDirectories.includes('node_modules'), 'Should exclude node_modules');
            assert.ok(excludedDirectories.includes('.git'), 'Should exclude .git');
            assert.ok(excludedDirectories.includes('target'), 'Should exclude target');
            assert.ok(excludedDirectories.includes('build'), 'Should exclude build');
            assert.ok(excludedDirectories.includes('dist'), 'Should exclude dist');
        });

        test('excludedFileExtensions should contain expected default exclusions', () => {
            assert.ok(excludedFileExtensions.includes('.exe'), 'Should exclude .exe');
            assert.ok(excludedFileExtensions.includes('.pdf'), 'Should exclude .pdf');
            assert.ok(excludedFileExtensions.includes('.env'), 'Should exclude .env');
            assert.ok(excludedFileExtensions.includes('.lock'), 'Should exclude .lock');
            assert.ok(excludedFileExtensions.includes('.zip'), 'Should exclude .zip');
        });
    });
});



Directory: test\suite
File: index.ts
==============
import * as path from 'path';
import Mocha from 'mocha';
import { glob } from 'glob';
export async function run(): Promise<void> {
    const mocha = new Mocha({
        ui: 'tdd',
        color: true,
        timeout: 60000
    });

    const testsRoot = path.resolve(__dirname, '.');
    try {
        const files = await glob('**/**.test.js', { cwd: testsRoot });
        
        // Add files to the test suite
        files.forEach(function (file) {
            mocha.addFile(path.resolve(testsRoot, file));
        });

        return new Promise<void>((resolve, reject) => {
            try {
                mocha.run((failures: number) => {
                    if (failures > 0) {
                        reject(new Error(`${failures} tests failed.`));
                    } else {
                        resolve();
                    }
                });
            } catch (err) {
                reject(err);
            }
        });
    } catch (err) {
        console.error('Error loading test files:', err);
        throw err;
    }
}

